"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[505792],{28453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>r});var a=n(296540);const i={},s=a.createContext(i);function o(e){const t=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(s.Provider,{value:t},e.children)}},850151:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>l,frontMatter:()=>o,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"ndc/admin/taxonomies/searchindex","title":"Search Index","description":"Netwrix Data Classification uses two mathematical principles to achieve its results:","source":"@site/docs/dataclassification/ndc/admin/taxonomies/searchindex.md","sourceDirName":"ndc/admin/taxonomies","slug":"/ndc/admin/taxonomies/searchindex","permalink":"/docs/dataclassification/ndc/admin/taxonomies/searchindex","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/dataclassification/ndc/admin/taxonomies/searchindex.md","tags":[],"version":"current","frontMatter":{},"sidebar":"dataClassificationSidebar","previous":{"title":"Search and Filter Taxonomies","permalink":"/docs/dataclassification/ndc/admin/taxonomies/searchandfiltertaxonomies"},"next":{"title":"Taxonomy Settings","permalink":"/docs/dataclassification/ndc/admin/taxonomies/settings"}}');var i=n(474848),s=n(28453);const o={},r="Search Index",c={},d=[];function h(e){const t={h1:"h1",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"search-index",children:"Search Index"})}),"\n",(0,i.jsx)(t.p,{children:"Netwrix Data Classification uses two mathematical principles to achieve its results:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Bayesian inference"}),"\n",(0,i.jsx)(t.li,{children:"Shannon\u2019s information theory"}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Bayesian inference is used to determine the weightings to be applied to individual words in the query so that the words that are most useful in identifying the required concepts receive the highest weightings. Initially, these weightings are based on the relative frequency of query terms as distributed across the entire index. Where relevance feedback information is available then these weightings are adjusted to tune the behaviour in favour of documents that are known to be relevant."}),"\n",(0,i.jsx)(t.p,{children:"Shannon\u2019s information theory is necessary when identifying concepts because the order in which words appear has a great effect on meaning."}),"\n",(0,i.jsx)(t.p,{children:"Nevertheless, the vast majority of retrieval systems available today would regard a document containing all words from a user\u2019s query to be 100% relevant \u2013 especially if all of the words are in close proximity. However, this is much too simplistic an approach for effective concept identification. For example, just because a sentence contains the words \u201cmoney\u201d and \u201corder\u201d does not necessarily mean that the topic is about \u201cmoney orders\u201d."}),"\n",(0,i.jsx)(t.p,{children:"Shannon\u2019s information theory states that the more frequently a sequence appears the less information, or entropy, it contains. Netwrix Data Classification uses this model to compute the incremental value of compound terms over their lower order components. In this way we are able to identify the word sequences that convey the most meaning and adjust the standard weightings accordingly."})]})}function l(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}}}]);